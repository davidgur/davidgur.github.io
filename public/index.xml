<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>David Gurevich</title>
    <link>https://www.gurevich.ca/</link>
    <description>Recent content on David Gurevich</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Copyright Â© 2024, David Gurevich</copyright>
    <lastBuildDate>Sat, 13 Dec 2025 00:10:57 -0500</lastBuildDate>
    <atom:link href="https://www.gurevich.ca/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Simple Outlier Detection in a Kalman Filter</title>
      <link>https://www.gurevich.ca/simple-outlier-detection-in-a-kalman-filter/</link>
      <pubDate>Sat, 13 Dec 2025 00:10:57 -0500</pubDate>
      <guid>https://www.gurevich.ca/simple-outlier-detection-in-a-kalman-filter/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve honestly spent a lot of time thinking about outliers and change detection in real-time data streams.&#xA;You can get into some pretty serious rabbit holes when thinking about this stuff.&#xA;If you&amp;rsquo;re not careful, you might accidentally end up in non-parametric land&#xA;with &lt;a href=&#34;https://arxiv.org/abs/1210.5552&#34;&gt;quickest change detection&lt;/a&gt; or some other crazy ideas&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;I think something a bit more down-to-earth&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; and maybe more applicable to our day-to-day work as scientists&#xA;and engineers is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Kalman_filter&#34;&gt;Kalman filter&lt;/a&gt; which takes sequential&#xA;measurements of some underlying process (where the measurement and process errors are Gaussian) and comes up,&#xA;basically, with increasingly precise estimates of the underlying value.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How do you buy a sweater?</title>
      <link>https://www.gurevich.ca/how-do-you-buy-a-sweater/</link>
      <pubDate>Wed, 22 Oct 2025 21:59:18 -0400</pubDate>
      <guid>https://www.gurevich.ca/how-do-you-buy-a-sweater/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;sean_connery.jpg&#34; alt=&#34;Sean Connery wearing a sweater&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;When I started writing this post, I was halfway through writing what&amp;rsquo;s basically an introductory article to non-parametric anomaly detection in a data stream.&#xA;I figure that I should write about more pressing matters, however, and so that&amp;rsquo;s why I&amp;rsquo;m writing this post about buying sweaters.&lt;/p&gt;&#xA;&lt;h3 id=&#34;whats-so-hard-about-buying-a-sweater-anyways&#34;&gt;What&amp;rsquo;s so hard about buying a sweater anyways?&lt;/h3&gt;&#xA;&lt;p&gt;This is a great question.&#xA;Completely reasonable, and if I was a better man, I&amp;rsquo;d be able to give you a good answer.&#xA;Unfortunately, I am the man that I am, and it is late October in New York City, I am cold, and I still don&amp;rsquo;t have a sweater.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Image Inpainting with Convex Optimization with Heuristics</title>
      <link>https://www.gurevich.ca/image-inpainting-with-convex-optimization-with-heuristics/</link>
      <pubDate>Thu, 17 Jul 2025 22:33:15 -0400</pubDate>
      <guid>https://www.gurevich.ca/image-inpainting-with-convex-optimization-with-heuristics/</guid>
      <description>&lt;p&gt;Image inpainting is the task of restoring missing or corrupted parts of an image.&#xA;State of the art methods are largely generative methods that are pretrained on&#xA;hundreds of thousands of images, and attempt to sample from the latent distribution&#xA;of the image. Rather than taking the &amp;ldquo;deep&amp;rdquo; approach, we will explore&#xA;methods that are entirely based on self-similarity measures.&#xA;The methods that we will explore are completely portable: they don&amp;rsquo;t require any&#xA;priors, and no pretrained model is necessary.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Signal Compression from a Linear Algebra Perspective</title>
      <link>https://www.gurevich.ca/signal-compression-from-a-linear-algebra-perspective/</link>
      <pubDate>Thu, 10 Jul 2025 21:31:30 -0400</pubDate>
      <guid>https://www.gurevich.ca/signal-compression-from-a-linear-algebra-perspective/</guid>
      <description>&lt;p&gt;One of my favourite courses from my time at the University of Waterloo was &lt;a href=&#34;https://uwflow.com/course/amath391&#34;&gt;AMATH 391&lt;/a&gt;.&#xA;At the time, it had the provocative title &lt;em&gt;From Fourier to Wavelets&lt;/em&gt;.&#xA;Nowadays, it has the more sober name &lt;em&gt;Data Analysis with Fourier and Wavelet Methods&lt;/em&gt;.&#xA;Honestly, this is probably a better name for the course anyways.&lt;/p&gt;&#xA;&lt;p&gt;I want to present to you a somewhat simple concept from this course.&lt;/p&gt;&#xA;&lt;p&gt;When we take the Fourier transformation of a signal \(f[t]\), we are finding the infinite dimensional &lt;em&gt;vector&lt;/em&gt;&#xA;that represents the signal in the Hilbert space of (usually) continuous functions (call it \(\mathcal{C}\))&#xA;Moreover, in the case of a Fourier analysis, we are representing this &lt;em&gt;vector&lt;/em&gt; using a &amp;ldquo;basis&amp;rdquo; of&#xA;infinitely many sinusoids.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
