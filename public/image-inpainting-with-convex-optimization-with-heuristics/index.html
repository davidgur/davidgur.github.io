<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Image Inpainting with Convex Optimization with Heuristics | David Gurevich</title>
<meta name="title" content="Image Inpainting with Convex Optimization with Heuristics" />
<meta name="description" content="Image inpainting is the task of restoring missing or corrupted parts of an image.
State of the art methods are largely generative methods that are pretrained on
hundreds of thousands of images, and attempt to sample from the latent distribution
of the image. Rather than taking the &ldquo;deep&rdquo; approach, we will explore
methods that are entirely based on self-similarity measures.
The methods that we will explore are completely portable: they don&rsquo;t require any
priors, and no pretrained model is necessary." />
<meta name="keywords" content="" />


<meta property="og:url" content="https://www.gurevich.ca/image-inpainting-with-convex-optimization-with-heuristics/">
  <meta property="og:site_name" content="David Gurevich">
  <meta property="og:title" content="Image Inpainting with Convex Optimization with Heuristics">
  <meta property="og:description" content="Image inpainting is the task of restoring missing or corrupted parts of an image. State of the art methods are largely generative methods that are pretrained on hundreds of thousands of images, and attempt to sample from the latent distribution of the image. Rather than taking the “deep” approach, we will explore methods that are entirely based on self-similarity measures. The methods that we will explore are completely portable: they don’t require any priors, and no pretrained model is necessary.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-07-17T22:33:15-04:00">
    <meta property="article:modified_time" content="2025-07-17T22:33:15-04:00">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Image Inpainting with Convex Optimization with Heuristics">
  <meta name="twitter:description" content="Image inpainting is the task of restoring missing or corrupted parts of an image. State of the art methods are largely generative methods that are pretrained on hundreds of thousands of images, and attempt to sample from the latent distribution of the image. Rather than taking the “deep” approach, we will explore methods that are entirely based on self-similarity measures. The methods that we will explore are completely portable: they don’t require any priors, and no pretrained model is necessary.">




  <meta itemprop="name" content="Image Inpainting with Convex Optimization with Heuristics">
  <meta itemprop="description" content="Image inpainting is the task of restoring missing or corrupted parts of an image. State of the art methods are largely generative methods that are pretrained on hundreds of thousands of images, and attempt to sample from the latent distribution of the image. Rather than taking the “deep” approach, we will explore methods that are entirely based on self-similarity measures. The methods that we will explore are completely portable: they don’t require any priors, and no pretrained model is necessary.">
  <meta itemprop="datePublished" content="2025-07-17T22:33:15-04:00">
  <meta itemprop="dateModified" content="2025-07-17T22:33:15-04:00">
  <meta itemprop="wordCount" content="1864">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  @import url('https://fonts.googleapis.com/css2?family=Work+Sans:ital,wght@0,100..900;1,100..900&display=swap');

  body {
    font-family: "Work Sans", sans-serif;
    font-optical-sizing: auto;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  body {

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  code.has-jax {font: inherit;
              font-size: 100%;
              background: inherit;
              border: inherit;
              color: #515151;
  }


  a {
    color: #3273dc;
     
  }

  .title {
    color: #222;
    text-decoration: none;
    border: 0;
  }

  .profile-link {
    text-decoration: none;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    .title {
      color: #fff;
    }

    .profile-link {
      text-decoration: none;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '\\(', right: '\\)', display: false},  
      ],
      throwOnError : false
    });
  });
</script>



  

  
</head>

<body>
  <header><h2> 
    <a href="/" class="title"> David Gurevich </a>
        <a href="mailto:david@gurevich.ca" style="text-decoration: none; width: 1.2em;" class="fas fa-at"></a> 
     <a href="https://www.linkedin.com/in/davidgur/" style="text-decoration: none; width: 1.2em;" class="fa fa-linkedin"></a> 
       <a href="https://github.com/davidgur" style="text-decoration: none; width: 1.2em;" class="fa fa-github"></a>   
       <a href="https://github.com/davidgur/resume/raw/master/resume.pdf" style="text-decoration: none; width: 1.2em;" class="far fa-file-pdf"></a> 
</h2>
<nav><a href="/">Home</a>


<a href="/blog">Blog</a>

</nav>
</header>
  <main>

<h1>Image Inpainting with Convex Optimization with Heuristics</h1>
<p>
  <i>
    <time datetime='2025-07-17' pubdate>
      2025-07-17
    </time>
  </i>
</p>

<content>
  <p>Image inpainting is the task of restoring missing or corrupted parts of an image.
State of the art methods are largely generative methods that are pretrained on
hundreds of thousands of images, and attempt to sample from the latent distribution
of the image. Rather than taking the &ldquo;deep&rdquo; approach, we will explore
methods that are entirely based on self-similarity measures.
The methods that we will explore are completely portable: they don&rsquo;t require any
priors, and no pretrained model is necessary.</p>
<p>We pose the image inpainting problem as an optimization problem.
To ensure that the problems are computationally tractable, we will aim for these
problems to be entirely convex.
Our exploration begins will begin with &ldquo;classroom&rdquo; examples of image inpainting with
convex optimization, and we develop several heuristics for our problem, until we
achieve visually satisfactory results.</p>
<p>We consider two kinds of image inpainting problems: random data loss, and rectangular
box inpainting.
Random data loss is representative of communication over a noisy channel, where we
lose pixels 50% of the time.
Rectangular box inpainting is a more explicit inpainting problem, where a user
would choose boxes that they would like the be filled in with something else.
This can be to erase unwanted features of an image.</p>
<p>We discover that within the image domain, first- and second-order differences are
usually sparse.
This is especially true for small holes (such as in data loss), or in large holes
with simple surroundings (such as a street with a shadow).</p>
<h2 id="test-images">Test Images</h2>
<p>We consider the following test images that we will perform inpainting on:
<img src="lena_test.png" alt="Lena Test Image">
<img src="nyc_test.png" alt="Street Test Image"></p>
<h2 id="section-1-minimizing-total-variation">Section 1: Minimizing Total Variation</h2>
<p>We begin by approaching the problem in the traditional, classroom way.
This is by minimizing what&rsquo;s called <em>total variation</em>.</p>
<p>Let \(U \in \mathbb{R}^{m \times n}\) be the matrix representing the reconstructed
image.
Then we define the total variation as
</p>
\[ \text{tv}(U) = \sum_{i=1}^{m-1} \sum_{j=1}^{n-1} \left\lVert \begin{matrix} U_{i+1,j} - U_{i,j} \\ U_{i,j+1} - U_{i,j} \end{matrix} \right\rVert. \]<p>
The effect of this is to minimize any &ldquo;large&rdquo; deviation between known and unknown
pixels.
We can now solve this convex optimization problem.
Let \( K \) be the set of \( (i, j) \) indices that are known.
Call \( U^{\text{orig}} \) containing the known matrix values that do not need to
be filled in.
Then our optimization problem is
</p>
\[ \begin{align*} \text{min} & \quad  \text{tv}(U) \\ \text{s.t.} & \quad U_{ij} = U_{ij}^{\text{orig}} \quad \forall (i, j) \in K \end{align*} \]<p>We can write this using CVXPY as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">inpaint_tv_rgb</span>(img):
</span></span><span style="display:flex;"><span>    img_rgb <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(img)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>
</span></span><span style="display:flex;"><span>    H, W, C <span style="color:#f92672">=</span> img_rgb<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> (np<span style="color:#f92672">.</span>sum(img_rgb, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Variables ---</span>
</span></span><span style="display:flex;"><span>    U <span style="color:#f92672">=</span> [cp<span style="color:#f92672">.</span>Variable((H, W)) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(C)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Objectives ---</span>
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    constraints <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C):
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#f92672">+=</span> cp<span style="color:#f92672">.</span>tv(U[c])
</span></span><span style="display:flex;"><span>        constraints <span style="color:#f92672">+=</span> [
</span></span><span style="display:flex;"><span>            cp<span style="color:#f92672">.</span>multiply(mask, U[c]) <span style="color:#f92672">==</span> cp<span style="color:#f92672">.</span>multiply(mask, img_rgb[:, :, c]),
</span></span><span style="display:flex;"><span>            U[c] <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>, U[c] <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Solve ---</span>
</span></span><span style="display:flex;"><span>    prob <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Problem(cp<span style="color:#f92672">.</span>Minimize(total_loss), constraints)
</span></span><span style="display:flex;"><span>    prob<span style="color:#f92672">.</span>solve(solver<span style="color:#f92672">=</span>cp<span style="color:#f92672">.</span>MOSEK, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Output ---</span>
</span></span><span style="display:flex;"><span>    u_val <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([np<span style="color:#f92672">.</span>clip(U[c]<span style="color:#f92672">.</span>value, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C)], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> u_val
</span></span></code></pre></div><p>The resulting image is
<img src="lena_sol1.png" alt="Lena First Solution"></p>
<p>We see quite good performance on small holes in the Lena image.
Now we examine performance on the NYC image with loss, which has more structure.
<img src="nyc_sol1.png" alt="NYC First Solution"></p>
<p>Here, we see that total variation is very effective at dealing with images with
randomized loss, at the very least, in the visual sense.
It would be difficult for someone to tell that the inpainted image was ever
corrupted to begin with.</p>
<p>Now we examine how total variation inpainting deals with large corrupted blocks.
<img src="nyc_sol1_block.png" alt="NYC First Solution Block"></p>
<p>Note that here, we see quite poor performance with large shadow regions.
This is a clear consequence of us using a naive total variation approach.
Regions with shadows create large variations, but these are <em>expected</em> variations,
so in our next steps, we should figure out a way to punish bad variation, while
encouraging &ldquo;expected&rdquo; variation.</p>
<h2 id="section-2-approximating-the-laplacian">Section 2: Approximating the Laplacian</h2>
<p>We saw that, in our previous attempts, minimizing total variation is effective in
mitigating random noise, but large, structural changes pose significant challenges.
In order to try to fix this, we can add an additional term penalizing the
Laplacian.
Hopefully, this will be effective in capturing larger variations in the image.</p>
<p>We numerically approximate the Laplacian by calculating variations in the \(x\)
direction and in the \(y\) direction.</p>
\[ \left\lVert \nabla \right\rVert^2 = \left\lVert \nabla_x \right\rVert^2 + \left\lVert \nabla_y \right\rVert^2, \]<p>
where
</p>
\[ \nabla_x^2 = U_{i-1,j} - 2U_{i,j} + U_{i+1,j}, \]<p>
and
</p>
\[ \nabla_y^2 = U_{i,j-1} - 2U_{i,j} + U_{i,j+1}. \]<p>We add a hyperparameter, \(\gamma\), which we will use to tune how much we want to
penalize the Laplacian.
In CVXPY, we can write this as</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">inpaint_tv_lap_rgb</span>(img):
</span></span><span style="display:flex;"><span>    img_rgb <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(img)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>
</span></span><span style="display:flex;"><span>    H, W, C <span style="color:#f92672">=</span> img_rgb<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> (np<span style="color:#f92672">.</span>sum(img_rgb, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Variables ---</span>
</span></span><span style="display:flex;"><span>    U <span style="color:#f92672">=</span> [cp<span style="color:#f92672">.</span>Variable((H, W)) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(C)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Objectives ---</span>
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    constraints <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Laplacian</span>
</span></span><span style="display:flex;"><span>        gamma <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
</span></span><span style="display:flex;"><span>        lap_x <span style="color:#f92672">=</span> U[c][:<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> U[c][<span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> U[c][<span style="color:#ae81ff">2</span>:, <span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        lap_y <span style="color:#f92672">=</span> U[c][<span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, :<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> U[c][<span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> U[c][<span style="color:#ae81ff">1</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>:]
</span></span><span style="display:flex;"><span>        lap <span style="color:#f92672">=</span> gamma <span style="color:#f92672">*</span> (cp<span style="color:#f92672">.</span>sum_squares(lap_x) <span style="color:#f92672">+</span> cp<span style="color:#f92672">.</span>sum_squares(lap_y))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#f92672">+=</span> cp<span style="color:#f92672">.</span>tv(U[c]) <span style="color:#f92672">+</span> lap
</span></span><span style="display:flex;"><span>        constraints <span style="color:#f92672">+=</span> [
</span></span><span style="display:flex;"><span>            cp<span style="color:#f92672">.</span>multiply(mask, U[c]) <span style="color:#f92672">==</span> cp<span style="color:#f92672">.</span>multiply(mask, img_rgb[:, :, c]),
</span></span><span style="display:flex;"><span>            U[c] <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>, U[c] <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Solve ---</span>
</span></span><span style="display:flex;"><span>    prob <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Problem(cp<span style="color:#f92672">.</span>Minimize(total_loss), constraints)
</span></span><span style="display:flex;"><span>    prob<span style="color:#f92672">.</span>solve(solver<span style="color:#f92672">=</span>cp<span style="color:#f92672">.</span>MOSEK, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Output ---</span>
</span></span><span style="display:flex;"><span>    u_val <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([np<span style="color:#f92672">.</span>clip(U[c]<span style="color:#f92672">.</span>value, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C)], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> u_val
</span></span></code></pre></div><p>We now examine the two NYC images:
<img src="nyc_sol2.png" alt="NYC Sol 2">
<img src="nyc_sol2_block.png" alt="NYC Sol 2 Block">
We see that, although the results didn&rsquo;t get worse, they didn&rsquo;t really get better,
either.</p>
<h2 id="section-3-total-generalized-variation">Section 3: Total Generalized Variation</h2>
<p>At this point, we try to introduce something called the Total Generalized Variation
(TGV).
This is an extension of TV, which attempts to balance first-order smoothness and
second-order smoothness using the \(l_1\) norm.</p>
<p>Total Variation will, as much as possible, try to create a piecewise constant block.
While this is effective for filling in small boxes in areas with little texture,
we see that this approach fails when texture information is present.
For example, with large shadows.
The Laplacian will then again smooth out flat regions.
This combination produces the smooth grey blocks that we see above.</p>
<p>Moreover, using the \(l_2\) norm for total variation and the Laplacian means that
the optimizer will &ldquo;spread&rdquo; errors out over all coordinates, which creates a
smoothing effect.</p>
<p>Total Generalized Variation, on the other hand, attempts to balance the first and
second-order effects while also promoting sparsity, by using the \(l_1\) norm.
The effect of using the \(l_1\) norm on first-order terms is that of allowing
large jumps in one direction, which means that edges will be preserved.
This is an assumption that the underlying structure is sparse.</p>
<p>If \(U\) is our image, then we&rsquo;ll let \(W\) approximate \(W \approx \nabla U\).
Then TGV can be written as
</p>
\[ \text{tgv}(U) = \alpha_1 \cdot \left\lVert \nabla U - W \right\rVert_1 + \alpha_2 \left\lVert \nabla W \right\rVert_1, \]<p>
where \(\alpha_1\) and \(\alpha_2\) are tuning parameters.</p>
<p>Notice that minimizing the total generalized variation will promote small, sparse
gradients, as well as small second-order effects.
We implement the TGV based image-inpainting algorithm below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">inpaint_tgv_rgb</span>(img):
</span></span><span style="display:flex;"><span>    img_rgb <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(img)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>
</span></span><span style="display:flex;"><span>    H, W, C <span style="color:#f92672">=</span> img_rgb<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> (np<span style="color:#f92672">.</span>sum(img_rgb, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Parameters ---</span>
</span></span><span style="display:flex;"><span>    alpha1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.5</span>
</span></span><span style="display:flex;"><span>    alpha2 <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Variables ---</span>
</span></span><span style="display:flex;"><span>    U <span style="color:#f92672">=</span> [cp<span style="color:#f92672">.</span>Variable((H, W)) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(C)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Objectives ---</span>
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    constraints <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- First-order</span>
</span></span><span style="display:flex;"><span>        DUx <span style="color:#f92672">=</span> U[c][<span style="color:#ae81ff">1</span>:, :] <span style="color:#f92672">-</span> U[c][:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, :]
</span></span><span style="display:flex;"><span>        DUy <span style="color:#f92672">=</span> U[c][:, <span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> U[c][:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        Wx <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Variable((H <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>, W))
</span></span><span style="display:flex;"><span>        Wy <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Variable((H, W <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Second-order</span>
</span></span><span style="display:flex;"><span>        DWx <span style="color:#f92672">=</span> Wx[:, <span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> Wx[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        DWy <span style="color:#f92672">=</span> Wy[<span style="color:#ae81ff">1</span>:, :] <span style="color:#f92672">-</span> Wy[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, :]
</span></span><span style="display:flex;"><span>        tgv_first_order <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>norm1(DUx <span style="color:#f92672">-</span> Wx) <span style="color:#f92672">+</span> cp<span style="color:#f92672">.</span>norm1(DUy <span style="color:#f92672">-</span> Wy)
</span></span><span style="display:flex;"><span>        tgv_second_order <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>norm1(DWx) <span style="color:#f92672">+</span> cp<span style="color:#f92672">.</span>norm1(DWy)
</span></span><span style="display:flex;"><span>        tgv_total <span style="color:#f92672">=</span> alpha1 <span style="color:#f92672">*</span> tgv_first_order <span style="color:#f92672">+</span> alpha2 <span style="color:#f92672">*</span> tgv_second_order
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Total</span>
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#f92672">+=</span> tgv_total
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Constraints</span>
</span></span><span style="display:flex;"><span>        constraints <span style="color:#f92672">+=</span> [
</span></span><span style="display:flex;"><span>            cp<span style="color:#f92672">.</span>multiply(mask, U[c]) <span style="color:#f92672">==</span> cp<span style="color:#f92672">.</span>multiply(mask, img_rgb[:, :, c]),
</span></span><span style="display:flex;"><span>            U[c] <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>, U[c] <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Solve ---</span>
</span></span><span style="display:flex;"><span>    prob <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Problem(cp<span style="color:#f92672">.</span>Minimize(total_loss), constraints)
</span></span><span style="display:flex;"><span>    prob<span style="color:#f92672">.</span>solve(solver<span style="color:#f92672">=</span>cp<span style="color:#f92672">.</span>MOSEK, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Output ---</span>
</span></span><span style="display:flex;"><span>    u_val <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([np<span style="color:#f92672">.</span>clip(U[c]<span style="color:#f92672">.</span>value, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C)], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> u_val
</span></span></code></pre></div><p><img src="nyc_sol3_block.png" alt="NYC Sol3 Block">
This is considerable improvement!
We see that the shadows in the bottom left-hand corner is filled in, in such a way
that preserves the shape of the shadow.
That being said, we do see some vertical and horizontal artifacts.
This is a consequence of the fact that we use the \(l_1\) norm in the \(x\) and
\(y\) directions, which promotes sparsity precisely in these directions.
If we were using the \(l_2\) norm as before, we would like be able to eliminate some
of these artifacts</p>
<h2 id="section-4-resolving-artifacts-in-tgv-inpainting">Section 4: Resolving Artifacts in TGV inpainting</h2>
<p>In order to eliminate the vertical and horizontal artifacts, we add a small \(l_2\)
total variation penalty.
This will penalize the vertical and horizontal lines that we see above.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">inpaint_tgv_tv_rgb</span>(img):
</span></span><span style="display:flex;"><span>    img_rgb <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(img)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>
</span></span><span style="display:flex;"><span>    H, W, C <span style="color:#f92672">=</span> img_rgb<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> (np<span style="color:#f92672">.</span>sum(img_rgb, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Parameters ---</span>
</span></span><span style="display:flex;"><span>    alpha1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.5</span>
</span></span><span style="display:flex;"><span>    alpha2 <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>    beta <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Variables ---</span>
</span></span><span style="display:flex;"><span>    U <span style="color:#f92672">=</span> [cp<span style="color:#f92672">.</span>Variable((H, W)) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(C)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Objectives ---</span>
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    constraints <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- (TGV) First-order</span>
</span></span><span style="display:flex;"><span>        DUx <span style="color:#f92672">=</span> U[c][<span style="color:#ae81ff">1</span>:, :] <span style="color:#f92672">-</span> U[c][:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, :]
</span></span><span style="display:flex;"><span>        DUy <span style="color:#f92672">=</span> U[c][:, <span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> U[c][:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        Wx <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Variable((H <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>, W))
</span></span><span style="display:flex;"><span>        Wy <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Variable((H, W <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- (TGV) Second-order</span>
</span></span><span style="display:flex;"><span>        DWx <span style="color:#f92672">=</span> Wx[:, <span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> Wx[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        DWy <span style="color:#f92672">=</span> Wy[<span style="color:#ae81ff">1</span>:, :] <span style="color:#f92672">-</span> Wy[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, :]
</span></span><span style="display:flex;"><span>        tgv_first_order <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>norm1(DUx <span style="color:#f92672">-</span> Wx) <span style="color:#f92672">+</span> cp<span style="color:#f92672">.</span>norm1(DUy <span style="color:#f92672">-</span> Wy)
</span></span><span style="display:flex;"><span>        tgv_second_order <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>norm1(DWx) <span style="color:#f92672">+</span> cp<span style="color:#f92672">.</span>norm1(DWy)
</span></span><span style="display:flex;"><span>        tgv_total <span style="color:#f92672">=</span> alpha1 <span style="color:#f92672">*</span> tgv_first_order <span style="color:#f92672">+</span> alpha2 <span style="color:#f92672">*</span> tgv_second_order
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Total Variation</span>
</span></span><span style="display:flex;"><span>        tv <span style="color:#f92672">=</span> beta <span style="color:#f92672">*</span> cp<span style="color:#f92672">.</span>tv(U[c])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Total</span>
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#f92672">+=</span> tgv_total <span style="color:#f92672">+</span> tv
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># --- Constraints</span>
</span></span><span style="display:flex;"><span>        constraints <span style="color:#f92672">+=</span> [
</span></span><span style="display:flex;"><span>            cp<span style="color:#f92672">.</span>multiply(mask, U[c]) <span style="color:#f92672">==</span> cp<span style="color:#f92672">.</span>multiply(mask, img_rgb[:, :, c]),
</span></span><span style="display:flex;"><span>            U[c] <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>, U[c] <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Solve ---</span>
</span></span><span style="display:flex;"><span>    prob <span style="color:#f92672">=</span> cp<span style="color:#f92672">.</span>Problem(cp<span style="color:#f92672">.</span>Minimize(total_loss), constraints)
</span></span><span style="display:flex;"><span>    prob<span style="color:#f92672">.</span>solve(solver<span style="color:#f92672">=</span>cp<span style="color:#f92672">.</span>MOSEK, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># --- Output ---</span>
</span></span><span style="display:flex;"><span>    u_val <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([np<span style="color:#f92672">.</span>clip(U[c]<span style="color:#f92672">.</span>value, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(C)], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> u_val
</span></span></code></pre></div><p><img src="nyc_sol4_block.png" alt="NYC Block 4">
Observe that adding a small total variation penalty has smoothed out the vertical
and horizontal artifacts.
Our final optimizer is thus
</p>
\[ \begin{align*} \text{min} & \quad  \text{tgv}(U) + \beta \cdot \text{tv}(U) \\ \text{s.t.} & \quad U_{ij} = U_{ij}^{\text{orig}} \quad \forall (i, j) \in K \end{align*} \]<p>
We can now test this inpainted on our remaining test images:
<img src="nyc_sol4.png" alt="NYC 4">
<img src="lena_sol4.png" alt="Lena 4"></p>
<h2 id="conclusion">Conclusion</h2>
<p>We see that we&rsquo;re able to perform image inpainting tasks that effectively preserve
first-order effects (straight edges) and partially preserve second-order effects
(textures).
Moreover, we can accomplish this without any priors, using only local information
within the image.</p>
<p>Since we use only local information (first and second order differences), large
holes will pose significant challenges for us.
Even small holes, if they contain significant texture information, will not
adequately be filled.
At that point, it would be more effective to use inpainting methods that take into
account global information, like PatchMatch, or even generative methods, like
GANs or stable diffusion.</p>
<p>That being said, large blocks with little texture information, or very small blocks
where first and second order approximations are adequate will be filled in very
effectively, as we have seen with the NYC holes and loss examples.</p>

</content>
<p>
  
</p>

  </main>
  <footer>
</footer>

    
</body>

</html>
